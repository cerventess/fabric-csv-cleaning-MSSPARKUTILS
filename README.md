# fabric-csv-cleaning-MSSPARKUTILS
Automatiser le nettoyage de fichiers CSV dans Microsoft Fabric avec mssparkutils.fs

# ğŸš€ Nettoyage Automatique de Fichiers CSV dans Microsoft Fabric avec mssparkutils.fs

Ce projet montre comment automatiser lâ€™ingestion et le nettoyage de fichiers CSV dans Microsoft Fabric Ã  lâ€™aide dâ€™un notebook PySpark et de la librairie `mssparkutils.fs`.

## ğŸ¯ Objectif

- Scanner un dossier `archiveRetail/` contenant des fichiers `.csv`
- Supprimer les lignes vides dans chaque fichier avec PySpark
- Sauvegarder les fichiers nettoyÃ©s au format `.parquet` dans `cleanedRetail/`
- Supprimer les fichiers CSV dâ€™origine aprÃ¨s traitement

## ğŸ“ Structure OneLake

```
Files/
â”œâ”€â”€ archiveRetail/        # Fichiers CSV bruts
â”œâ”€â”€ cleanedRetail/        # Fichiers nettoyÃ©s en Parquet
```

## ğŸ§° Outils utilisÃ©s

| Outil | Description |
|-------|-------------|
| `mssparkutils.fs.ls()` | Liste les fichiers |
| `spark.read.csv()`     | Lecture des CSV |
| `dropna(how="all")`    | Suppression des lignes vides |
| `.write.parquet()`     | Export des fichiers nettoyÃ©s |
| `mssparkutils.fs.rm()` | Suppression des fichiers bruts |

## ğŸ’¡ Exemple d'exÃ©cution

Une fois lancÃ© dans un notebook Fabric, le script va :
1. Lister tous les fichiers CSV dans `Files/archiveRetail/`
2. Nettoyer chaque fichier
3. Sauvegarder le rÃ©sultat dans `Files/cleanedRetail/`
4. Supprimer le fichier original

## ğŸ› ï¸ DÃ©pendances

- Microsoft Fabric
- Un Lakehouse avec les dossiers `archiveRetail/` et `cleanedRetail/`
- Runtime PySpark (dans notebook Fabric)

## ğŸ“· Capture d'Ã©cran

*(Ajoutez une image de votre notebook ou de la structure OneLake ici)*

## ğŸ“Œ Auteur

Oussema Chtioui  
[ğŸ”— Profil LinkedIn](https://www.linkedin.com/in/oussama-chtioui-91a256aa/)  
[ğŸ† #MVPFabricSeries](https://www.linkedin.com/feed/hashtag/mvpfabricseries/)
